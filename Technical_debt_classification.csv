issue_key,debt_type,debt_indicator,text_content,time_spent_on_repayment_after_debt_reported (h),existing_debt_in_the_system,debt_reported_by_creators,debt_location,resolve_status,resolved_by,notes
CAMEL-1256,Code,Duplicated code,"The camel-cxf component is dued for some code cleanup and refactoring.   We can clean some of of the interfaces and redundant code, etc.",107,Yes,No,System,Resolved,Identifiers,
CAMEL-1317,Documentation,Outdated documentation,We can definitely do this in Camel already... just need an example/docs for it.,5,Yes,No,System,Resolved,Identifiers,
CAMEL-1320,Documentation,Outdated documentation,"And we need to add it to the wiki page as well, under data formats.",16,No,No,System,Resolved,Creators,
CAMEL-1669,Requirement,Requirement partially implemented,The only feature which we don't support is correlated message groups. That requires a bit more work and also may complicated the configuration a bit as you would need to configure- expression to evaluate the correlation keyAnd then the throttler logic need to have a map of correlation key -> TimeSlot,-,No,No,System,Unresolved,-,
CAMEL-1669,Test,Lack of tests,"But I just wanted to say that anything we change in the model, we must have unit tests to cover that change in both camel-core (Java DSL) and camel-spring (XML DSL). ",19,No,No,Patch,Resolved,Creators,
CAMEL-1846,Documentation,Outdated documentation,The maven reports is just getting to old and intermixed with 1.x and trunk releases. We should just remove them as they dont bring much value anyway.The xsddoc has been removed from the build files. So its now a matter of removing from the apache http site (people with credentials is needed),-,Yes,No,System,Unresolved,-,
CAMEL-1881,Test,Lack of tests,"@Stan, maybe you want to add a unit test?  ",15,No,No,Patch,Resolved,Creators,
CAMEL-201,Code,Low-quality code ,Only two issues with the ident of the code.One @override was not idented properly. And one method parameter was on a new line instead of singleline. Just nitpicking.,19,No,No,Patch,Resolved,Creators,
CAMEL-201,Documentation,Outdated documentation,Would love to have it documented on the wiki that we got this new transform DSL now.And we should remember to add it to the release notes that setOutBody() is depreacted and replaced with transform(),37,No,No,System,Resolved,Creators,
CAMEL-201,Test,Lack of tests, There are no XQuery specific tests (mainly because of not knowing where to put them,23,No,Yes,Patch,Resolved,Creators,
CAMEL-2163,Documentation,Outdated documentation,Stan lets add an example to camel-jdbc and camel-sql wiki pages how to use the split(body()) to process each row one by one.,53,Yes,No,System,Resolved,Identifiers,
CAMEL-231,Documentation,Low-quality documentation,Broken link on wiki page for Type Converter,21,Yes,No,System,Resolved,Identifiers,
CAMEL-2446,Test,Lack of tests,"I have smoke tested the examples, but is there a general unit test that will validate that the context file?",-,No,Yes,Patch,Unresolved,-,Not committed 
CAMEL-2535,Code,Dead code,"As we don't use the CxfSoap component any more, it's time to clean it up.",38,Yes,No,System,Resolved,Identifiers,
CAMEL-3033,Design,Non-optimal decisions,"If you take a look at CXF FaultOutInterceptor and WebFaultOutInterceptor, you will find CXF already did that kind of thing for you.Such as setting the fault message with fault cause message , and building up the fault detail, all you need to do is make sure that your fault is thrown rightly from CxfConsumer.",14,No,No,Patch,Resolved,Creators,
CAMEL-3033,Test,Lack of tests,Can you write a small test case to demonstrate that current camel-cxf can't handle the fault rightly?,14,No,No,Patch,Resolved,Creators,
CAMEL-3217,Test,Low coverage,Johan you are a committer now. Can you port your unit test to Apache?,-,Yes,No,System,Unresolved,-,
CAMEL-3351,Code,Duplicated code,removing dupe code.,396,No,No,Patch,Resolved,Identifiers,
CAMEL-3351,Code,Dead code,Removed unused imports,396,No,No,Patch,Resolved,Identifiers,
CAMEL-383,Code,Low-quality code ,Also anyone got a better name for the option (transferExchange)?,23,No,No,Patch,Resolved,Others,
CAMEL-383,Documentation,Outdated documentation,TODO: Remember to update wiki component documentation with the new option if patch is accepted,194,No,No,System,Resolved,Identifiers,
CAMEL-3888,Documentation,Low-quality documentation,Tighten up @deprecated in camel-core to add more details what alternatives to use-----Description-----Author: Claus IbsenWe should ensure all deprecated classes/methods in camel-core is documented what alternatives to use. Also if possible give a hint when it could be removed.,1220,Yes,No,System,Resolved,Identifiers,
CAMEL-4132,Architecture,Using obsoleted technology,The camel-atom component is using an ancient incubator version of abdera which will make it hard to work with camel-cxf.   Updating to 1.1.2 which is what CXF uses would help.,19,Yes,No,System,Resolved,Others,
CAMEL-4331,Build,Over- or under-declared dependencies,"Avoid the redundant direct dependency on log4j by the components (of the scope 'test'), as it's transitively given for free through the slf4j-log4j12 dependency with the RIGHT / COMPLIANT version-----Description-----Author: Babak VahdatSee the discussion here http://camel.465427.n5.nabble.com/Camel-freemarker-td4693216.html-----Comment No.0-----To last: -14h-----Author: Babak VahdatI didn't remove the log4j dependencies by the pom's of camel-web & camel-web-standalone, as there it's of the scope 'compile'. I assume these 2 declared dependencies were on purpose!----------------------------------------------------------------------------------------------------Submitted commit  fe1b4094ea855ec34667c4091ac304da05b10940Author: Claus Ibsen <davsclaus@apache.org>Link:             https://github.com/apache/camel/commit/fe1b4094ea855ec34667c4091ac304da05b10940CAMEL-4331: Remove log4j test scoped dependency in pom.xml as slf4j-log4j provides it. Thanks to Babak for the patch.",14,Yes,No,System,Resolved,Identifiers,
CAMEL-4543,Architecture,Violation of modularity,"It would be good if these were moved into their own module, something like camel-aries-namespace or the like.",123,Yes,No,System,Resolved,Identifiers,
CAMEL-4593,Architecture,Using obsoleted technology,We need to upgrade the the abdera to 1.1.3 once it is out.,13825,Yes,No,System,Resolved,Others,
CAMEL-4826,Documentation,Low-quality documentation,"Tech edits of JavaDoc and other code comments -- lets -> (let's, allow, {})",98,Yes,No,System,Resolved,Identifiers,
CAMEL-493,Documentation,Outdated documentation,The camel mail component registers nntp as a supported protocol but there is no javacode or documentation how to use it,-,Yes,No,System,Unresolved,-,
CAMEL-5205,Code,Dead code,Remove legacy code in DefaultEndpoint in createExchange(Exchange) method,1,Yes,No,System,Resolved,Identifiers,
CAMEL-5207,Architecture,Violation of modularity,"These files in src/main/data is part of testing, and should be in src/test/data instead",2,Yes,No,System,Resolved,Identifiers,
CAMEL-5539,Design,Non-optimal decisions,"I also see the current solution is not enough robust. when halfOpen is reached, (System.currentTimeMillis() - lastFailure < halfOpenAfter) there is no restriction on the number of calls (threads) that will perform a retry.When retry timeout is reached, we should let only 1 thread go in ""halfOpen"" mode, all other should be kept in ""open"" state until an halfOpen succeed.(will create new issue for this)",-,No,No,System,Unresolved,-,
CAMEL-5539,Requirement,Requirement partially implemented,My implementation is completed but I'll leave this issue open in case other implementation as mentioned above are to be added.,-,No,No,System,Unresolved,-,
CAMEL-5714,Code,Low-quality code,Throw a meaningful exception when the conetxt component cannot create a right endpoint,1,Yes,No,System,Resolved,Identifiers,
CAMEL-6194,Build,Over- or under-declared dependencies,"It would be better if the patch does not introduce new JAR dependency, eg as you do with google guava. ",288,No,No,Patch,Resolved,Creators,
CAMEL-6194,Test,Lack of tests,I'll write up some unit tests later this week.,4744,No,Yes,Patch,Resolved,Others,
CAMEL-6735,Defect,Uncorrected known defects,This works in 2.12.x onwards. Hunting this down on 2.11.x is low priority. End users is encourage to upgrade if they really need this.,-,Yes,No,System,Unresolved,-,
CAMEL-6973,Documentation,Outdated documentation,"because 2.12.x was being cut for a 2.12.2 release because of that a few things were not done (integrating into 2.12.x, updating the documentation).",-,Yes,No,System,Unresolved,-,
CAMEL-7300,Code,Low-quality code,Not this patch makes use of a deprecated API call. In time we should move the entire camel-hl7 component to the new HAPI API: CAMEL-7301,-,No,Yes,System,Unresolved,-,
CAMEL-7412,Documentation,Outdated documentation,"The docs state camel-jdbc does not support transactions.-----Description-----Author: Torsten Mielke. The docs at http://camel.apache.org/jdbc.html state {quote}This component can not be used as a Transactional Client. If you need transaction support in your route, you should use the SQL component instead.{quote}This statement however seems to be wrong. I have a demo at https://github.com/tmielke/fuse-demos/tree/master/Camel/Camel-JMS-JDBC-XA-TX that uses the camel-jdbc component in an XA transaction scenario without errors.",25,Yes,No,System,Resolved,Identifiers,
CAMEL-7690,Documentation,Low-quality documentation,A plain JAR example. As a WAB is not simple to create.,-,No,Yes,System,Unresolved,-,
CAMEL-7813,Defect,Uncorrected known defects,"For some reasons I can see the issue is still in 2.16.1.When Camel sends a reply it keeps JMSRepyTo/ReplyTo on the JMS Message.Have to add though that I'm using the activemq component, version 5.12.1.",-,Yes,No,System,Unresolved,-,
CAMEL-7954,Documentation,Outdated documentation,"Component updated, need to update documentation",-,No,Yes,System,Unresolved,-,
CAMEL-8101,Documentation,Outdated documentation,We need to update the documentation with the new commandhttp://camel.apache.org/mongodb,1616,No,No,System,Resolved,Creators,
CAMEL-8260,Code,Low-quality code,"The EIP model in camel-core has getter/setter for all the options. That should be plain getter/setter style without having a boolean isFoo() for an easy boolean simple type check. As the latter we cannot determine if the Foo value was set or not, as the isFoo() boolean has to return a value.We should simply just remove those boolean isFoo() and let it be 100% plain getter/setter with the given types.",1,Yes,No,System,Resolved,Identifiers,
CAMEL-8370,Documentation,Outdated documentation,"I’m using the camel-netty4-http (latest 2.14.2-SNAPSHOT) component to create an endpoint that receives an HTTP POST from a device, translates the message from binary to JSON, then sends it along to a kafka topic for further processing.  When there are errors in validating or translating the incoming message, I need to be able to return a HTTP response code and response body.The camel-netty4-http documentation has an “Access to Netty types” section, which says that I should be able to do the following to access the instance of io.netty.handler.codec.http.HttpResponse:    HttpResponse response = exchange.getIn(NettyHttpMessage.class).getHttpResponse();Regardless of where I access the exchange within the route, getHttpResponse() is always returning null.  On the ""happy path” I can return 200 by calling exchange.getOut().setBody(myResponse), but I have been unable to figure out how to return another response code.Is this a bug?  Or is there another way to accomplish what I’m trying to do?{quote}After digging around in the code, it looks like the HTTP status code is set via the CamelHttpResponseCode message header (org.apache.camel.component.netty4.http.DefaultNettyHttpBinding, line 308).  However, there is no mention of this message header in either the camel-netty-http or camel-netty4-http documentation.  It would be helpful to add this header to the list of applicable message headers, and also to include an example that demonstrates how to set the response status code and body:Finally, the existing ""Access to Netty types"" example should be modified to be clear that only the request can be accessed in this way.",-,Yes,No,System,Unresolved,-,
CAMEL-903,Documentation,Outdated documentation,TODO: Need to document it in wiki,13,No,Yes,System,Resolved,Creators,
CAMEL-910,Code,Low-quality code,"#4Maybe the exchange pattern InOnly, InOut is not easily understood by new users and non JBI/ServiceMix end-users. Maybe use terms such as sync/async instead (and list the MEP in parathes)",7,Yes,No,System,Resolved,Others,
CAMEL-910,Documentation,Low-quality documentation,"#2I think the 2 parts in the introduction should be listed as bullets (one for JMS, one for webservice)#3spelling (comman in the sentence below)credit agency , and banks)",8,Yes,No,System,Resolved,Others,
CAMEL-9226,Test,Lack of tests,"When using the MetricsRoutePolicyFactory to collect metrics from routes, all metrics for the last route in a multicast record double the expected value.-----Comment No.0-----To last: -1.1d-----Author: Jon McEwen. Attempted to recreate the problem in a unit test, but it passes: https://github.com/jonmcewen/camel/commit/8496f9705c2906424f40deb10a9d1215c1371c61-----Comment No.1-----To last: -1.0d-----Author: Jon McEwenI. had messed up my dependencies and picked up version 2.15.3 of camel-metrics.  I can confirm this was fixed in 2.16.0-----Comment No.2-----To last: -1.0d-----Author: Claus Ibsen. Ah good to hear. You are welcome to submit your unit test as a PR / .patch file then we can add it to camel-metrics so we have it there too.",6,Yes,No,System,Resolved,Identifiers,
CAMEL-9412,Documentation,Low-quality documentation,Correct camel-example-swagger-cdi documentation-----Description-----Author: Greg A. fix some typocorrect url,3,Yes,No,System,Resolved,Identifiers,
CAMEL-960,Code,Low-quality code ,"Hadrian, yes the unit test is what we want, but I do think that this behavior should be configurable from- a new fluent build syntax to indicate its handled.- a special header on the message to indicate its handled (eg you can do some java coding in a processor and set that you handled it or not)- onException should *not* handle it by default (but interesting thought)- failureHandled fluent syntax also supports a predicate so you can use So something like a *failureHandled* fluent builderAlso on the *onException* that I think is a cool featureAnd to let end users do some java coding of their own and set a special header to indicate handled or notAnd with the predicate for the fluent builderAlso supporting on the onException as well:BTW: The fix should be in restoreExceptionOnExchange in DeadLetterChannel.",21,No,No,Patch,Resolved,Creators,
HADOOP-10067,Build,Over- or under-declared dependencies,Compiling for Fedora revels a missing declaration for javax.annotation.Nullable.  This is the result of a missing explicit dependency on jsr305.,496,Yes,No,System,Resolved,Identifiers,
HADOOP-10139,Documentation,Low-quality documentation,"The document should be understandable to a newcomer because the first place he will go is ""setup a single node"".",1417,Yes,No,System,Resolved,Identifiers,
HADOOP-10169,Code,Complex code,can be simplified to the following so there aren't so many return statements to track:,9,No,Yes,Patch,Resolved,Creators,
HADOOP-10211,Code,Low-quality code ,"Why catch and silently ignore IllegalArgumentException?  The user wants privacy or integrity, but typos it, it's not very secure to silently fallback to none.  I'd let the exception be thrown.",457,No,No,Patch,Resolved,Creators,
HADOOP-10423,Documentation,Low-quality documentation,"Clarify compatibility policy document for combination of new client and old server.-----Description-----Author: Chris Nauroth. As discussed on the dev mailing lists and MAPREDUCE-4052, we need to update the text of the compatibility policy to discuss a new client combined with an old server.",3,Yes,No,System,Resolved,Identifiers,
HADOOP-10474,Code,Dead code,"The classes in o.a.h.record have been deprecated for more than a year and a half. They should be removed. As the first step, the jira moves all these classes into the hadoop-streaming project, which is the only user of these classes.",7,Yes,No,System,Resolved,Identifiers,
HADOOP-10485,Code,Dead code,Hadoop-streaming no longer requires many classes in o.a.h.record. This jira removes the dead code.,-,Yes,No,System,Unresolved,-,
HADOOP-10508,Test,Lack of tests,Can you please provide a unit test for this functionality?,120,No,No,Patch,Resolved,Creators,
HADOOP-10673,Code,Low-quality code ,"One minor comment: both {{rpcMetrics}} and {{rpcDetailedMetrics}} are not final field, so how about adding null check before accessing them?",4,No,No,Patch,Resolved,Creators,
HADOOP-10674,Code,Slow algorithm,"Summary-----Author: Tsz-wo Sze. Rewrite the PureJavaCrc32 loop for performance improvement-----Description-----Author: Tsz-wo Sze. Below are some performance improvement opportunities performance improvement in PureJavaCrc32.- eliminate ""off += 8; len -= 8;""- replace T8_x_start with hard coded constants- eliminate c0 - c7 local variablesIn my machine, there are 30% to 50% improvement for most of the cases.",365,Yes,No,System,Resolved,Identifiers,
HADOOP-10674,Code,Low-quality code ,It will be better to change the following code to. Other than that +1.,1,No,No,Patch,Resolved,Creators,
HADOOP-10729,Test,Lack of tests,Add tests for PB RPC in case version mismatch of client and server,12884,Yes,No,System,Resolved,Identifiers,
HADOOP-10809,Code,Low-quality code ,"Hi, [~ehans].  Nice work!  I have just a few comments remaining.# findbugs-exclude.xml: There is a minor typo in a comment: ""interate"" intsead of ""iterate"".# {{Wasb}}: The new imports in this class appear to be unneeded.# In the {{FileSystem}} service provider configuration file, I recommend adding this line, so that we get automatic loading of the classes for the ""wasbs"" scheme too:# Going along with the above, I recommend removing the {{fs.wasb.impl}} and {{fs.wasbs.impl}} configuration properties from azure-test.xml.  Now that we have the service provider configuration file, these are no longer necessary for the tests to be able to load the classes, and removing them gives us a good test that the service provider configuration file is working as expected.Additionally, there are a few items from earlier rounds of feedback that still need to be addressed:# {{NativeAzureFileSystem#seek}}: Please wrap the debug log statement in a check for {{if (LOG.isDebugEnabled())}}.# {{PageBlobOutputStream}}: In the constructor, let's remove the commented-out assignment of {{this.ioQueue}}.# {{PageBlobOutputStream.WriteRequest#runInternal}}: There is just one line left in here that goes over 80 characters.  Can this be wrapped please?# {{PageBlobOutputStream#killIoThreads}}: This method has a comment saying that it's only intended for unit tests. Would you please add the {{VisibleForTesting}} annotation to this method?# {{TestNativeAzureFileSystemOperationsMocked}}: There are some TODO comments about things done ""during manual merge"". Is it appropriate to remove these comments now?# Let's update README.txt to mention page blob support and discuss the new configuration property for setting paths to use page blobs.  We could also mention intended use cases for one vs. the other (i.e. Block blobs are good for scans/MapReduce and page blobs are good for random access/HBase.)# There is a potential internationalizaton issue on this line:-should be fixed to {{toLower(LOCALE.EN_US)}}",3,No,No,Patch,Resolved,Creators,
HADOOP-10809,Code,Low-quality code ,"There were a few other broad suggestions that came up earlier in discussion.  Let's defer these to separate issues at a later time, because there is already a lot happening in this patch:# Convert to slf4j logging.# Use executors instead of directly using thread pools.# Start using the new file system contract tests.",-,No,No,Patch,Unresolved,-,
HADOOP-10819,Build,Over- or under-declared dependencies,"Looks like it could  maybe be this error, in which case it is a missing build-time dependency in hadoop",-,Yes,No,System,Unresolved,-,
HADOOP-10930,Requirement,Non-functional requirements not being fully satisfied,"{{PositionedReadable}} definition requires the implementations for its interfaces should be thread-safe.HarFsInputStream doesn't implement these interfaces with tread-safe, this JIRA is to fix this.",-,Yes,No,System,Unresolved,-,
HADOOP-10930,Test,Low coverage,"Also, if you are going to work on the HarFS, can you look at the new contract tests added in HADOOP-9361 and have a go at subclassing those tests with a set for HarFS? That will catch other issues (e.g it looks like it is only throwing {{IOException}} on out-of-range operations, not the preferred {{EOFException}}. Doing that would get you past the ""no tests"" warning on jenkins, and ensure that HarFS is in sync with current expectations",-,Yes,No,System,Unresolved,-,
HADOOP-10931,Build,Over- or under-declared dependencies,"use command ”mvn package -Pdist,native -DskipTests -Dtar“ to compile hadoop, it have errors as below:[ERROR] /home/hadoop-common/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/util/SwiftTestUtils.java:[41,7] cannot access org.hamcrest.Matcherclass file for org.hamcrest.Matcher not found",83,Yes,No,System,Resolved,Identifiers,
HADOOP-11014,Code,Low-quality code ,"Hi [~ozawa], thank you for the patch. Would you mind import ""org.apache.hadoop.io.IOUtils"" in the beginning of this file and replace ""org.apache.hadoop.io.IOUtils.closeStream(out)"" with ""IOUtils.closeStream(out)"".",-,No,No,Patch,Unresolved,-,
HADOOP-11074,Architecture,Violation of modularity,"Now that hadoop-aws has been created, we should actually move the relevant code into that module, similar to what was done with hadoop-openstack, etc.",51,Yes,No,System,Resolved,Identifiers,
HADOOP-11074,Test,Low coverage,"can you add an {{\@Ignore}} on the tests which are failing, so that we can have a green upstream build?  Then file a JIRA to fix these tests later so we get full coverage on this feature.",-,No,No,Patch,Unresolved,-,
HADOOP-11074,Documentation,Low-quality documentation,"Let's address the javadoc warnings in HADOOP-11082.  This is not new code, so it seems likely to be a build XML / configuration issue.  Since {{test-patch.sh}} compares the old and new javadoc count, the fact that this adds a few more warnings won't make anyone else's build red.",-,No,No,Patch,Unresolved,-,
HADOOP-11103,Documentation,Outdated documentation,RemoteException has a number of undocumented behaviors,5846,Yes,No,System,Resolved,Identifiers,
HADOOP-11103,Test,Low coverage,Some of the test code doesn't check for correct error codes to correspond with the wrapped exception type,5846,Yes,No,System,Resolved,Identifiers,
HADOOP-11295,Code,Low-quality code ,"- Use of the qualifier {{final}} is inconsistent. More variables (conf, clientN) can be made final, or get rid of it.- Variable {{addr}} is used only once, please inline it as a parameter of {{getProxy}} for clarity- Don't swallow {{InterruptedException}} around in the {{while}} loops around sleep they can be legit. I think It's fine to to remove try/catch and have the test fail.- 1000 millis is a little excessive. Let us do 100- Move the client interrupt/join logic into the finally block past server.stop. Then you actually don't need to call client.interrupt  because client calls will exit on its own.- Use client.join() without the timeout parameter, we are already protected by the Test timeout from blocking indefinitely.",1,No,No,Patch,Resolved,Creators,
HADOOP-11409,Test,Low coverage,"The unit test should have an Assert.fail call or something similar after the getFileContext call, otherwise the lack of throwing an exception for a bad fs URI will still pass the test.""Excpected"" s/b ""Expected""",5,No,No,Patch,Resolved,Creators,
HADOOP-11421,Design,Non-optimal decisions,"We should have a drop-in replacement for File#listDir that doesn't hide IOExceptions, and which returns a ChunkedArrayList rather than a single large array.",0,Yes,No,System,Resolved,Identifiers,
HADOOP-11421,Documentation,Low-quality documentation,Couple other things:* Need {{<p/>}} tag for javadoc linebreak* I read the docs at http://docs.oracle.com/javase/7/docs/api/java/nio/file/DirectoryStream.html and it'd be nice to do like the example and unwrap the DirectoryIteratorException into an IOException.,-,No,No,System,Unresolved,-,
HADOOP-11690,Design,Non-optimal decisions,There appears to be an opportunity of code reduction by re-implementing Groups to use the IdMappingServiceProvider.,-,Yes,No,System,Unresolved,-,
HADOOP-11740,Documentation,Low-quality documentation,"2. Those unnecessary Javadoc are there to conform Javadoc conventions and format. In future someone may fill them. I suggest we don't remove them, you can find so many in the project.-----Comment No.8-----To last: -3.6d-----Author: Zhe ZhangThanks Kai for the review!I read the test classes again and figured out more about the structure. Let me know if it looks OK now.Regarding Javadoc I believe we shouldn't have empty statements when merging to trunk. If a parameter or return value is self-descriptory, I think it's better not to add a Javadoc than adding an empty one. But let's discuss that separately since it's not in the scope of this JIRA.",-,No,No,Patch,Unresolved,-,
HADOOP-11764,Design,Non-optimal decisions,We need to avoid using daemon-specific and/or project-specific environment variables.  This is the #1 reason why the branch-2 shell code is just utter chaos.,159,No,No,Patch,Resolved,Creators,Not committed 
HADOOP-11984,Test,Expensive tests,I see recent hadoop-hdfs test runs have been taking ~2.5 hours.  This one was ~45 minutes.,3226,Yes,No,System,Resolved,Identifiers,
HADOOP-12135,Code,Low-quality code,removed hadoop hard-codes,21,Yes,No,System,Resolved,Identifiers,
HADOOP-12135,Code,Low-quality code ,"If someone wants to take this patch over and rewrite to be more pythonic, please do!",-,No,Yes,Patch,Unresolved,-,
HADOOP-12268,Code,Dead code ,Would you remove unused imports in TestHDFSContractAppend and AbstractContractAppendTest?,92,No,No,Patch,Resolved,Creators,
HADOOP-12268,Documentation,Low-quality documentation,"Would you please fix the following javadoc comment?""concat"" should be ""append"".",92,No,No,Patch,Resolved,Creators,
HADOOP-12672,Documentation,Low-quality documentation,I agree to improve documentation to make it clear that the rpc timeout is disabled by default (for compatibility reason).,-,No,No,System,Unresolved,-,
HADOOP-12837,Defect,Uncorrected known defects,revisiting this. It's a wontfix I'm afraid. Sorry,-,Yes,No,System,Unresolved,-,
HADOOP-12888,Test,Lack of tests,"Yetus will complain about the lack of tests, but we'll have to go with that.",-,No,No,Patch,Unresolved,-,
HADOOP-12923,Architecture,Violation of modularity,Some code is used only by tests.  Let's relocate them.,5,Yes,No,System,Resolved,Identifiers,
HADOOP-2815,Design,Non-optimal decisions,Extending the Trash API might be ok in the short term but does not sound too appealing from a long-term perspective.,-,No,No,Patch,Unresolved,-,Not committed 
HADOOP-3198,Code,Low-quality code ,This will lead to very unmaintainable code. We absolutely do not want to have nested retries for different contexts.,-,No,No,Patch,Unresolved,-,Not committed 
HADOOP-3315,Architecture,Violation of modularity,"bq. Looking at the latest patch, I have one question: there are a lot of contained classes and interfaces in tfile. Why are these all contained in one tfile class, instead of making tfile a package and having the classes and interfaces contained in there?Fair question, the code could be factored to make it easier to maintain. However, I am a bit hesitant to split them into packages (tfile itself is already a package, adding more sub-packages would probably be a bit overkill).After examining the code, here are a few opportunities where we could split it out:- Move out Interface RawComparable.- Move out public class ByteArray- Move out the exception classes: MetaBlockAlreadyExists, MetaBlockDoesNotExist- Move out the code that dumps the meta info of TFile (possibly with a wrapper class called TFileDumper).I will start working on the above and feel free to comment on what more could be done.",66,No,Yes,Patch,Resolved,Creators,
HADOOP-3315,Code,Duplicated code ,"Then CompressionCodecFactory should be extended, rather than duplicated.",-,No,No,Patch,Unresolved,-,
HADOOP-481,Design,Non-optimal decisions,Instead of passing a long[] you should pass a struct that implements Writable.  ,76,No,No,Patch,Resolved,Creators,Not committed 
HADOOP-6105,Code,Low-quality code ,"1.Check for null in addDeprecation method.2.Some extra lines are there in front of some of the methods , remove them3.Try to use foreach kind of syntax where ever possible.It makes code look simpler.",163,No,No,Patch,Resolved,Creators,
HADOOP-6105,Test,Lack of tests,- Need one test case for testing mapping of one key to more than one new keys. This must be tested for both set and get. I would suggest a new test case for this.,28,No,No,Patch,Resolved,Creators,
HADOOP-6220,Test,Lack of tests,no tests as there is no easy way to generate the race condition.,-,No,No,Patch,Unresolved,-,
HADOOP-6229,Code,Low-quality code ,I believe the original code isn't defensive enough and there's a possibility for NPE to be thrown if {{Path f}} happens to be {{null}}. I'd add an extra check for this as the very first line of the method.,21,No,No,Patch,Resolved,Creators,
HADOOP-6279,Test,Lack of tests,Does not include unit tests,-,Yes,No,System,Unresolved,-,
HADOOP-6299,Documentation,Outdated documentation,"Some javadoc could be added in the UserGroupInformation class but other than that, I think it is ready. ",23,No,No,Patch,Resolved,Creators,
HADOOP-6381,Code,Duplicated code ,I am concerned about the code duplication this brings.,-,No,No,Patch,Unresolved,-,Not committed 
HADOOP-6730,Code,Dead code ,* Lines 135-138: This code:  is a no-op and should be removed.,17,No,No,Patch,Resolved,Creators,
HADOOP-6730,Code,Low-quality code ,"the provided methods (setUp() and tearDown()) conflict with the provided names.* Lines 55 & 56: These values should be all capitalized and final. Alternatively, it may be good to provide these values via functions so that implementing classes may override as needed.* Line 64: catch should be on the same line as closing brace, per our coding style* Line 70: fc should not be declared static. It is the responsibility of each implementing class to provide an instance of it. Also, fc should probably be protected* Line 91: Please provide assert message for assertion failure* Since this is a test that the copy method worked, we should prove it by comparing the contents of the copied file with the original.",17,No,No,Patch,Resolved,Creators,
HADOOP-6730,Test,Lack of tests,"Thanks to Eli, He noticed that there is no test for FileContext#Copy operation. ",75,Yes,No,System,Resolved,Others,
HADOOP-6869,Code,Low-quality code ,you are writing some content into this file which seems to be an inadvertent side-effect. Doesn't look like a good idea.,103,No,No,Patch,Resolved,Creators,
HADOOP-6869,Code,Duplicated code ,"instead of duplicating their exact implementation. You have done similar in {{DaemonProtocolAspect}} already.- Also, in {{DaemonProtocolAspect}} you already have a ref to the filesystem so you can just call its {{createFile}} methods instead of implementing your own logic ",103,No,No,Patch,Resolved,Creators,
HADOOP-7115,Code,Low-quality code ,- ensureInitialized has a formatting issue (cacheTimeout is on the same line as the opening if),10290,No,No,Patch,Resolved,Others,
HADOOP-7115,Design,Non-optimal decisions,"- instead of using ints for {{USER}} and {{GROUP}}, how about an enum like this:this way you get typesafety, and you can just stringify the {{IdCache}} instance to get a printable name",0,No,No,Patch,Resolved,Creators,
HADOOP-7118,Test,Lack of tests,This JIRA is to fix the bug and add a unit test for writeXml in common (apparently it never had a unit test),9,Yes,No,System,Resolved,Identifiers,
HADOOP-7375,Code,Low-quality code ,Nit: lines 568 and 2231 need indenting.,44,No,No,Patch,Resolved,Creators,
HADOOP-7560,Architecture,Violation of modularity,"Currently hadoop-common is a JAR module, thus it cannot aggregate sub-modules.Changing it to POM module it makes it an aggregator module, all the code under hadoop-common must be moved to a sub-module.",122,Yes,No,System,Resolved,Identifiers,
HADOOP-7560,Documentation,Outdated documentation,"It doesn't looks like BUILDING.txt was updated with this, can you please update.",-,No,No,System,Unresolved,-,
HADOOP-7786,Architecture,Violation of modularity,"After removing these I noticed the rest of FsConfig is only used once outside a test, and isn't tagged as a public API, I think we can remove it entirely.",4309,Yes,No,System,Resolved,Identifiers,
HADOOP-7786,Code,Dead code,"HADOOP-4952 added a couple HDFS-specific configuration values to common (the block size and the replication factor) that conflict with the HDFS values (eg have the wrong defaults, wrong key name), are not used by common or hdfs and should be removed.",4308,Yes,No,System,Resolved,Identifiers,
HADOOP-7919,Code,Dead code,"The following only resides in core-default.xml and doesn't look like its used anywhere at all. At least a grep of the prop name and parts of it does not give me back anything at all.These settings are now configurable via generic Log4J opts, via the shipped log4j.properties file in the distributions.",466,Yes,No,System,Resolved,Identifiers,
HADOOP-7924,Code,Low-quality code ,- {{svc1}} and {{svc2}} aren't very descriptive parameter names - maybe {{fromSvc}} and {{toSvc}} or {{oldActive}} and {{newActive}}?,140,No,No,Patch,Resolved,Creators,
HADOOP-7930,Requirement,Requirement partially implemented,"Currently the check done in the *hasSufficientTimeElapsed()* method is hardcoded to 10 mins wait.The wait time should be driven by configuration and its default value, for clients should be 1 min.",6826,Yes,No,System,Resolved,Others,
HADOOP-7974,Code,Low-quality code,Also fixed some diff-surrounding whitesp. and indentation issues),0,Yes,No,System,Resolved,Identifiers,
HADOOP-8124,Code,Dead code,The Syncable.sync() was deprecated in 0.21.  We should remove it.,24,Yes,No,System,Resolved,Identifiers,
HADOOP-8168,Code,Low-quality code ,Although I'd suggest maybe something like this to avoid spurious whitespace:,2540,No,No,Patch,Resolved,Creators,
HADOOP-8236,Documentation,Outdated documentation,"Nit: can remove the ""TODO"" before transitionToActive since this is now configurable.",35,No,No,Patch,Resolved,Creators,
HADOOP-8288,Code,Dead code,Remove references of mapred.child.ulimit etc. since they are not being used any more,47,Yes,No,System,Resolved,Identifiers,
HADOOP-8350,Code,Low-quality code ,"A couple of nits: in TestNetUtils, there is a magic number of 200 in assertTimeSince, and on assertReadTimeout maybe call the second parameter expectedMillis (since its not clear if it's nanos or millis).",1,No,No,Patch,Resolved,Creators,
HADOOP-8364,Build,Poor deployment practice,"This is a matter of maintainability and understandability, and therefore robustness under future changes in build.xml.  No substantial change in functionality is proposed.",-,Yes,No,System,Unresolved,-,
HADOOP-8597,Code,Low-quality code ,Jenkins says that org.apache.hadoop.fs.shell.Display$AvroFileInputStream should be static.,1,No,No,Patch,Resolved,Identifiers,
HADOOP-8597,Test,Lack of tests,This looks like a useful addition.  Can you please add a unit test for it?,67,No,No,Patch,Resolved,Creators,
HADOOP-8726,Code,Low-quality code ,"# A few nits on the style and consistency.  Should add a space around one of the ""!="", and use a cuddled ""if"".Regarding {{getCredentials}}:  The existing {{getTokens}} is returning an immutable list prevent the caller from directly tampering with the UGI's tokens.  {{getCredentials}} must also return a copy to avoid leaking tokens into the wrong UGI.  Ex.  Let's say I want to get the tokens from one UGI, add more tokens, and then use those with a new UGI.  With the change in this patch, the original UGI will now also contain the new tokens only intended for the new/other UGI.  You'll probably need to add a private {{getCredentialsInternal}} that fetches from the {{Subject}}, and the public {{getCredentials}} returns {{new Credentials(getCredentialsInternal())}}.",23,No,No,Patch,Resolved,Identifiers,
HADOOP-8726,Code,Duplicated code ,# {{UGI.getLoginUser}} should call {{UGI.addCredentials}} instead of duplicating the logic of that method.,23,No,No,Patch,Resolved,Identifiers,
HADOOP-8726,Test,Lack of tests,"I'll write some test, but it would be great if you can test with specific use case.",22,No,No,Patch,Resolved,Identifiers,
HADOOP-8866,Code,Slow algorithm,"SampleQuantiles#query() does O(N) calls LinkedList#get() in a loop, rather than using an iterator. This makes query O(N^2), rather than O(N).",75,Yes,No,System,Resolved,Identifiers,
HADOOP-8921,Defect,Uncorrected known defects,"Hi Giri, does the latest patch looks good to you?  Could you commit it?",-,Yes,No,System,Unresolved,-,
HADOOP-9042,Code,Low-quality code ,"Can remove the import of Assume or convert the test to junit4, otherwise +1",0,No,No,Patch,Resolved,Creators,
HADOOP-9042,Test,Lack of tests,Add a unit test to make sure {{umask}} is working correctly in FileSystemContractBaseTest.,1344,Yes,No,System,Resolved,Identifiers,
HADOOP-9254,Test,Low coverage,"Cover packages org.apache.hadoop.util.bloom, org.apache.hadoop.util.hash",5939,Yes,No,System,Resolved,Identifiers,
HADOOP-9259,Code,Low-quality code,the teardown code in FileSystemContractBaseTest assumes that {{fs!=null}} and that it's OK to throw an exception if the delete operation fails. Better to check the {{fs}} value and catch and convert an exception in the {{fs.delete()}} operation to a {{LOG.error()}} instead.This will stop failures in teardown becoming a distraction from the root causes of the problem (that your FileSystem is broken),1635,Yes,No,System,Resolved,Identifiers,
HADOOP-9305,Code,Complex code,"ATM, what about opening a JIRA to clean this spaghetti of conditionals replacing it with a MAP and a simple struct having the needed settings?",-,Yes,No,System,Unresolved,-,
HADOOP-9364,Code,Low-quality code ,"instead of globUri.getPath().equals(""""), we can use globUri.getPath().isEmpty().  I changed it in the new patch.",11,No,No,Patch,Resolved,Identifiers,
HADOOP-9369,Test,Lack of tests,"Hi Karthik, the patch seems fine to me, and I agree that the patch is so simple and writing a test sufficiently difficult that it seems unnecessary to write a test for this.",-,No,No,Patch,Unresolved,-,
HADOOP-9669,Code,Dead code ,5. it would be nice to remove the extra copy for writeFixedOpaque,-,No,No,Patch,Unresolved,-,
HADOOP-9669,Documentation,Low-quality documentation,"1. please try to keep the original javadoc for the same named methods2. can you make ""State state"" as final?3. please fix the javadoc /** check if the rest of data has more than <len> bytes */""len"" is not visible in generated javadoc",2,No,No,Patch,Resolved,Creators,
HADOOP-9683,Code,Low-quality code ,"Minor nit: it'll be nice to preserve the ""bytes read"" in the exception log in Listener#doRead.",112,No,No,Patch,Resolved,Creators,
HADOOP-9683,Documentation,Low-quality documentation,* server#processConnectionContext  - the exception thrown is RpcReply exception - in the javadoc please specify that it throws the rpcReplyException whch wrap the AccessControlException and which other one (does not seem to be RpcDeserializationException as mentioned in Javadoc).,5,No,No,Patch,Resolved,Creators,
HADOOP-9748,Code,Multi-thread correctness,"Description-----Author: Daryn Sharp. EnsureInitialized is always sync'ed on the class, when it should only sync if it actually has to initialize.-----Comment No.0-----To last: -20h-----Author: Daryn Sharp. Minor change.  This helps reduce unnecessary class lock contention between such common methods as {{UGI#getGroupNames}} and {{UGI.getCurrentUser}}, etc.",20,Yes,No,System,Resolved,Identifiers,
HADOOP-9763,Architecture,Violation of modularity,"Nicholas, this should be moved to hadoop-common, right?",-,Yes,No,System,Unresolved,-,
HADOOP-9763,Code,Low-quality code ,2. It would be better if we can add an upper limit for the size of the GSet. This can guarantee NN continues to function even when a large amount of retry requests come within a short period of time.,7,No,No,Patch,Resolved,Creators,
HADOOP-9763,Documentation,Low-quality documentation,"if more javadoc/comments can be added to TestLightWeightCache, such as the general steps for each check process, and what is tested for each step.",10,No,No,Patch,Resolved,Creators,
HADOOP-9763,Test,Lack of tests,Still need to test it.,63,No,Yes,Patch,Resolved,Creators,
HADOOP-9791,Test,Low coverage,Add a test case covering long paths for new FileUtil access check methods-----Description-----Author: Ivan Mitic. We’ve seen historically that paths longer than 260 chars can cause things not to work on Windows if not properly handled. Filing a tracking Jira to add a native io test case with long paths for new FileUtil access check methods added with HADOOP-9413.,1229,Yes,No,System,Resolved,Identifiers,
HADOOP-9820,Code,Low-quality code ,"# SaslRpcClient.SaslRpc*Stream should be named SaslRpcClient.Wrapped*Stream.# The default stream buffer size should be configurable instead of hard coded ""64*1024"".",22,No,No,Patch,Resolved,Creators,
HADOOP-9883,Code,Low-quality code ,The two things I'd recommend are using 2 spaces for indentation and following the 80 char limit per line.,-,No,No,Patch,Unresolved,-,Not committed 